{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMuiP5jobPSI8l3AZqmS6Ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkf87/agents-course-ko/blob/main/multi_agent_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í™˜ê²½ì„¤ì •\n"
      ],
      "metadata": {
        "id": "GDKHMH6rk4jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install smolagents gradio"
      ],
      "metadata": {
        "id": "zORNSEuylabo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhcjKevXk1Su"
      },
      "outputs": [],
      "source": [
        "from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, HfApiModel\n",
        "import json\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "vsDp7C6PnOzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_search_agent():\n",
        "    # ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸\n",
        "    return ToolCallingAgent(\n",
        "        tools=[DuckDuckGoSearchTool()],\n",
        "        model=HfApiModel()\n",
        "    )\n",
        "\n",
        "def create_writer_agent():\n",
        "    # íŒŒì¼ ì‘ì„±ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸\n",
        "    return CodeAgent(\n",
        "        tools=[],  # CodeAgentëŠ” ê¸°ë³¸ì ìœ¼ë¡œ íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
        "        model=HfApiModel()\n",
        "    )\n",
        "\n",
        "def create_analyzer_agent():\n",
        "    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì •ë¦¬í•˜ëŠ” ì—ì´ì „íŠ¸\n",
        "    return ToolCallingAgent(\n",
        "        tools=[],  # ë¶„ì„ ì—ì´ì „íŠ¸ëŠ” íŠ¹ë³„í•œ ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©\n",
        "        model=HfApiModel()\n",
        "    )\n",
        "\n",
        "def expand_query(agent, original_query, progress_logs=None):\n",
        "    # ì›ë³¸ ì¿¼ë¦¬ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì„¸ë¶€ ì¿¼ë¦¬ë¡œ í™•ì¥\n",
        "    expansion_prompt = f\"\"\"\n",
        "    ë‹¤ìŒ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ëœ 4ê°œì˜ êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
        "    ê°ê°ì˜ ì¿¼ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´ì´ë‚˜ ê´€ì ì„ ë‹¤ë¤„ì•¼ í•˜ë©°, ì‹¤ì œ ê²€ìƒ‰ì— íš¨ê³¼ì ì¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "    ê²€ìƒ‰ì–´: {original_query}\n",
        "\n",
        "    ì‘ë‹µ í˜•ì‹:\n",
        "    1. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.\n",
        "    2. ê° ì¿¼ë¦¬ëŠ” ê²€ìƒ‰ ì—”ì§„ì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    3. ì¿¼ë¦¬ëŠ” í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\n",
        "    {{\n",
        "        \"queries\": [\n",
        "            \"êµ¬ì²´ì ì¸ ì²« ë²ˆì§¸ ê²€ìƒ‰ì–´\",\n",
        "            \"êµ¬ì²´ì ì¸ ë‘ ë²ˆì§¸ ê²€ìƒ‰ì–´\",\n",
        "            \"êµ¬ì²´ì ì¸ ì„¸ ë²ˆì§¸ ê²€ìƒ‰ì–´\",\n",
        "            \"êµ¬ì²´ì ì¸ ë„¤ ë²ˆì§¸ ê²€ìƒ‰ì–´\"\n",
        "        ]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    if progress_logs is not None:\n",
        "        progress_logs.append(\"\\n==== ì¿¼ë¦¬ í™•ì¥ í”„ë¡œì„¸ìŠ¤ ====\")\n",
        "        progress_logs.append(f\"[í™•ì¥ ìš”ì²­ í”„ë¡¬í”„íŠ¸]\\n{expansion_prompt}\")\n",
        "\n",
        "    try:\n",
        "        # ì—ì´ì „íŠ¸ ì‘ë‹µ ë°›ê¸°\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(\"\\n[ì—ì´ì „íŠ¸ì—ê²Œ ì¿¼ë¦¬ í™•ì¥ ìš”ì²­ ì¤‘...]\")\n",
        "\n",
        "        result = agent.run(expansion_prompt)\n",
        "\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ì—ì´ì „íŠ¸ ì‘ë‹µ - RAW]\\n{result}\")\n",
        "            progress_logs.append(\"\\n[JSON íŒŒì‹± ì‹œë„ ì¤‘...]\")\n",
        "\n",
        "        parsed_result = json.loads(result)\n",
        "\n",
        "        if \"queries\" not in parsed_result or not parsed_result[\"queries\"]:\n",
        "            if progress_logs is not None:\n",
        "                progress_logs.append(\"\\n[ì˜¤ë¥˜] JSONì— 'queries' í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©.\")\n",
        "            return [original_query]\n",
        "\n",
        "        queries = parsed_result[\"queries\"]\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ì¶”ì¶œëœ ì¿¼ë¦¬ - í•„í„°ë§ ì „]\\n{json.dumps(queries, ensure_ascii=False, indent=2)}\")\n",
        "\n",
        "        # ë¹ˆ ì¿¼ë¦¬ë‚˜ ë„ˆë¬´ ì§§ì€ ì¿¼ë¦¬ í•„í„°ë§\n",
        "        queries = [q for q in queries if q and len(q) > 2]\n",
        "\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[í•„í„°ë§ í›„ ì¿¼ë¦¬]\\n{json.dumps(queries, ensure_ascii=False, indent=2)}\")\n",
        "\n",
        "        if not queries:\n",
        "            if progress_logs is not None:\n",
        "                progress_logs.append(\"\\n[í•„í„°ë§ í›„ ìœ íš¨í•œ ì¿¼ë¦¬ ì—†ìŒ] ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©.\")\n",
        "            return [original_query]\n",
        "\n",
        "        return queries\n",
        "\n",
        "    except Exception as e:\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ì¿¼ë¦¬ í™•ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ] {str(e)}\\nì›ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "        return [original_query]\n",
        "\n",
        "def analyze_results(agent, search_results, progress_logs=None):\n",
        "    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìœ ìš©í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
        "    analysis_prompt = f\"\"\"\n",
        "    ì•„ë˜ ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ê³  ê°€ì¥ ì¤‘ìš”í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "    ë¶„ì„ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:\n",
        "    1. ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ë°˜ë³µë˜ëŠ” ì •ë³´ëŠ” ì‹ ë¢°ì„±ì´ ë†’ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "    2. ìµœì‹  ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.\n",
        "    3. ì¶œì²˜ê°€ ëª…í™•í•œ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.\n",
        "    4. ê° ë°œê²¬ì‚¬í•­ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ë‹´ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
        "    5. ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì œì™¸í•˜ì„¸ìš”.\n",
        "\n",
        "    ê²€ìƒ‰ ê²°ê³¼:\n",
        "    {json.dumps(search_results, indent=2, ensure_ascii=False)[:100000]}  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì‚¬ìš©\n",
        "\n",
        "    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\n",
        "    {{\n",
        "        \"key_findings\": [\n",
        "            {{\n",
        "                \"content\": \"ì²« ë²ˆì§¸ ë°œê²¬ì‚¬í•­ì˜ ìƒì„¸ ë‚´ìš©\",\n",
        "                \"reliability\": \"ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ\",\n",
        "                \"source\": \"ë°œê²¬ëœ ì¶œì²˜ (ì•Œ ìˆ˜ ìˆëŠ” ê²½ìš°)\"\n",
        "            }},\n",
        "            {{\n",
        "                \"content\": \"ë‘ ë²ˆì§¸ ë°œê²¬ì‚¬í•­ì˜ ìƒì„¸ ë‚´ìš©\",\n",
        "                \"reliability\": \"ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ\",\n",
        "                \"source\": \"ë°œê²¬ëœ ì¶œì²˜ (ì•Œ ìˆ˜ ìˆëŠ” ê²½ìš°)\"\n",
        "            }},\n",
        "            ...ê³„ì†...\n",
        "        ]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    if progress_logs is not None:\n",
        "        progress_logs.append(\"\\n==== ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ====\")\n",
        "        progress_logs.append(\"[ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸ - í—¤ë”ë§Œ í‘œì‹œ (ì „ì²´ ê¸¸ì´ê°€ ë„ˆë¬´ ê¹€)]\\n\" + analysis_prompt.split(\"ê²€ìƒ‰ ê²°ê³¼:\")[0])\n",
        "        progress_logs.append(f\"\\n[ë¶„ì„í•  ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜] {len(search_results)}ê°œ\")\n",
        "\n",
        "    try:\n",
        "        # ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì‹œë„\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(\"\\n[ì—ì´ì „íŠ¸ì—ê²Œ ë¶„ì„ ìš”ì²­ ì¤‘...]\")\n",
        "\n",
        "        result = agent.run(analysis_prompt)\n",
        "\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ì—ì´ì „íŠ¸ ë¶„ì„ ì‘ë‹µ - RAW]\\n{result}\")\n",
        "            progress_logs.append(\"\\n[JSON íŒŒì‹± ì‹œë„ ì¤‘...]\")\n",
        "\n",
        "        # JSON íŒŒì‹± ì‹œë„\n",
        "        try:\n",
        "            parsed_result = json.loads(result)\n",
        "\n",
        "            if progress_logs is not None:\n",
        "                progress_logs.append(f\"\\n[JSON íŒŒì‹± ì„±ê³µ]\\n{json.dumps(parsed_result, ensure_ascii=False, indent=2)[:1000]}...\")\n",
        "\n",
        "            if \"key_findings\" in parsed_result and parsed_result[\"key_findings\"]:\n",
        "                # JSON êµ¬ì¡°ê°€ ì˜ˆìƒëŒ€ë¡œì¸ ê²½ìš°\n",
        "                if progress_logs is not None:\n",
        "                    progress_logs.append(\"\\n[ì˜ˆìƒ JSON êµ¬ì¡° í™•ì¸ë¨] 'key_findings' í‚¤ ìˆìŒ\")\n",
        "\n",
        "                findings = []\n",
        "                for item in parsed_result[\"key_findings\"]:\n",
        "                    if isinstance(item, dict) and \"content\" in item:\n",
        "                        # ì‹ ë¢°ë„ ì •ë³´ ì¶”ê°€\n",
        "                        reliability = item.get(\"reliability\", \"\")\n",
        "                        source = item.get(\"source\", \"\")\n",
        "\n",
        "                        content = item[\"content\"]\n",
        "                        if reliability and source:\n",
        "                            findings.append(f\"{content} (ì‹ ë¢°ë„: {reliability}, ì¶œì²˜: {source})\")\n",
        "                        elif reliability:\n",
        "                            findings.append(f\"{content} (ì‹ ë¢°ë„: {reliability})\")\n",
        "                        elif source:\n",
        "                            findings.append(f\"{content} (ì¶œì²˜: {source})\")\n",
        "                        else:\n",
        "                            findings.append(content)\n",
        "                    elif isinstance(item, str) and item:\n",
        "                        findings.append(item)\n",
        "\n",
        "                if progress_logs is not None:\n",
        "                    progress_logs.append(f\"\\n[ì²˜ë¦¬ëœ ë°œê²¬ì‚¬í•­] {len(findings)}ê°œ í•­ëª© ì¶”ì¶œë¨\")\n",
        "\n",
        "                if findings:\n",
        "                    return findings\n",
        "            elif \"key_findings\" in parsed_result and isinstance(parsed_result[\"key_findings\"], list):\n",
        "                # ë‹¨ìˆœ ë¬¸ìì—´ ëª©ë¡ì¸ ê²½ìš°\n",
        "                if progress_logs is not None:\n",
        "                    progress_logs.append(\"\\n[ë‹¨ìˆœ ëª©ë¡ êµ¬ì¡° í™•ì¸ë¨] ë¬¸ìì—´ ëª©ë¡ ì²˜ë¦¬ ì¤‘\")\n",
        "\n",
        "                findings = [item for item in parsed_result[\"key_findings\"] if item and len(str(item)) > 10]\n",
        "\n",
        "                if progress_logs is not None:\n",
        "                    progress_logs.append(f\"\\n[í•„í„°ë§ í›„ ë°œê²¬ì‚¬í•­] {len(findings)}ê°œ í•­ëª© ì¶”ì¶œë¨\")\n",
        "\n",
        "                if findings:\n",
        "                    return findings\n",
        "            else:\n",
        "                if progress_logs is not None:\n",
        "                    progress_logs.append(\"\\n[ì˜ˆìƒê³¼ ë‹¤ë¥¸ JSON êµ¬ì¡°] 'key_findings' í‚¤ê°€ ì—†ê±°ë‚˜ ë‹¤ë¥¸ í˜•ì‹\")\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            # JSON íŒŒì‹±ì— ì‹¤íŒ¨í•œ ê²½ìš°, ì¤„ ë‹¨ìœ„ë¡œ ì˜ë¯¸ ìˆëŠ” ì •ë³´ ì¶”ì¶œ ì‹œë„\n",
        "            if progress_logs is not None:\n",
        "                progress_logs.append(\"\\n[JSON íŒŒì‹± ì‹¤íŒ¨] í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ì „í™˜\")\n",
        "\n",
        "        # JSON íŒŒì‹±ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì˜ˆìƒ êµ¬ì¡°ê°€ ì•„ë‹Œ ê²½ìš°, í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œë„\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(\"\\n[í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ì‹œì‘] ì¤„ ë‹¨ìœ„ ë¶„ì„\")\n",
        "\n",
        "        lines = result.split(\"\\n\")\n",
        "        findings = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            # ì˜ë¯¸ ìˆëŠ” ì¤„ë§Œ ì¶”ì¶œ (ì§§ì€ ì¤„, JSON í‘œê¸°, ë¹ˆ ì¤„ ì œì™¸)\n",
        "            if line and len(line) > 30 and not (line.startswith('{') or line.startswith('}') or line.startswith('[') or line.startswith(']')):\n",
        "                findings.append(line)\n",
        "\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼] {len(findings)}ê°œ ì˜ë¯¸ ìˆëŠ” ì¤„ ì¶”ì¶œë¨\")\n",
        "\n",
        "        if findings:\n",
        "            return findings\n",
        "\n",
        "        # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(\"\\n[ë¶„ì„ ì‹¤íŒ¨] ëª¨ë“  ë¶„ì„ ë°©ë²• ì‹¤íŒ¨. ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜\")\n",
        "\n",
        "        return [\"ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ] {str(e)}\")\n",
        "\n",
        "        return [f\"ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"]\n",
        "\n",
        "def generate_report(writer_agent, query, findings, expanded_queries, progress_logs=None):\n",
        "    \"\"\"\n",
        "    ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” í’ë¶€í•œ ë³´ê³ ì„œ ìƒì„±\n",
        "    \"\"\"\n",
        "    report_prompt = f\"\"\"\n",
        "    ë‹¤ìŒ ì£¼ì œì™€ ë°œê²¬ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
        "\n",
        "    ì£¼ì œ: {query}\n",
        "\n",
        "    ì¡°ì‚¬ì— ì‚¬ìš©ëœ ê²€ìƒ‰ì–´:\n",
        "    {expanded_queries}\n",
        "\n",
        "    ë°œê²¬ëœ ì£¼ìš” ì •ë³´:\n",
        "    {chr(10).join([f\"- {finding}\" for finding in findings])}\n",
        "\n",
        "    ë³´ê³ ì„œëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:\n",
        "    1. ì œëª©: ì£¼ì œë¥¼ ì˜ ë‚˜íƒ€ë‚´ëŠ” ëª…í™•í•œ ì œëª© (êµµì€ ê¸€ì”¨)\n",
        "    2. ê°œìš”: ì£¼ì œì— ëŒ€í•œ ì†Œê°œì™€ ì¡°ì‚¬ì˜ ë°°ê²½ ë° ëª©ì  (ìµœì†Œ 200ì ì´ìƒ)\n",
        "    3. ì£¼ìš” ë°œê²¬ì‚¬í•­: ê°€ì¥ ì¤‘ìš”í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë¥¼ ìƒì„¸íˆ ì„¤ëª… (ê° í•­ëª©ë‹¹ ìµœì†Œ 200ì ì´ìƒ, ì´ 5ê°œ ì´ìƒì˜ í•­ëª©)\n",
        "    4. ì„¸ë¶€ ë¶„ì„:\n",
        "       a. ì •ë³´ì˜ ì‹ ë¢°ì„± í‰ê°€ (ì†ŒìŠ¤ ë¶„ì„, êµì°¨ ê²€ì¦ ê²°ê³¼)\n",
        "       b. ë°œê²¬ëœ ìŸì ì´ë‚˜ ë…¼ë€ (ìˆëŠ” ê²½ìš°)\n",
        "       c. ì‹œê°„ì  ë³€í™”ë‚˜ ì¶”ì„¸ (ê´€ë ¨ì´ ìˆëŠ” ê²½ìš°)\n",
        "       d. ì§€ì—­ì /ë¬¸í™”ì  ì°¨ì´ì  (ê´€ë ¨ì´ ìˆëŠ” ê²½ìš°)\n",
        "    5. í†µí•©ì  ë¶„ì„: ëª¨ë“  ë°œê²¬ì‚¬í•­ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ì‹¬ì¸µ í•´ì„ (ìµœì†Œ 500ì ì´ìƒ)\n",
        "    6. ê²°ë¡  ë° ì œì–¸: ì „ì²´ ë‚´ìš©ì˜ ìš”ì•½ê³¼ í–¥í›„ ì£¼ëª©í•  ì  ë˜ëŠ” ê¶Œì¥ì‚¬í•­ (ìµœì†Œ 400ì ì´ìƒ)\n",
        "    7. ì´ ë³´ê³ ì„œì˜ í•œê³„: ì •ë³´ ìˆ˜ì§‘ ê³¼ì •ì˜ ì œí•œì‚¬í•­ì´ë‚˜ í–¥í›„ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•œ ë¶€ë¶„\n",
        "\n",
        "    ë³´ê³ ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­:\n",
        "    - ê° ì„¹ì…˜ë§ˆë‹¤ ì¶©ë¶„í•œ ë‚´ìš©ê³¼ ê¹Šì´ë¥¼ í¬í•¨í•  ê²ƒ (ì „ì²´ ë³´ê³ ì„œëŠ” ìµœì†Œ 5000ì ì´ìƒ)\n",
        "    - ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ ì‚¬ì‹¤ë“¤ì„ ì—°ê²°í•˜ê³  í•´ì„í•˜ëŠ” í†µí•©ì  ë¶„ì„ì„ ì œê³µí•  ê²ƒ\n",
        "    - ê°€ëŠ¥í•œ ê²½ìš° ì¶œì²˜ì™€ ë‚ ì§œë¥¼ í¬í•¨í•  ê²ƒ\n",
        "    - ì „ë¬¸ ìš©ì–´ê°€ ìˆë‹¤ë©´ ê°„ëµíˆ ì„¤ëª…í•  ê²ƒ\n",
        "    - ê°ê´€ì ì´ê³  ê· í˜• ì¡íŒ ê´€ì ì—ì„œ ì„œìˆ í•  ê²ƒ\n",
        "    \"\"\"\n",
        "\n",
        "    if progress_logs is not None:\n",
        "        progress_logs.append(\"\\n==== ë³´ê³ ì„œ ìƒì„± í”„ë¡œì„¸ìŠ¤ ====\")\n",
        "        progress_logs.append(\"[ë³´ê³ ì„œ ì‘ì„± ìš”ì²­ í”„ë¡¬í”„íŠ¸]\\n\" + report_prompt.split(\"ë°œê²¬ëœ ì£¼ìš” ì •ë³´:\")[0] + \"ë°œê²¬ëœ ì£¼ìš” ì •ë³´: [...]\")\n",
        "        progress_logs.append(f\"\\n[ì²˜ë¦¬í•  ë°œê²¬ì‚¬í•­ ìˆ˜] {len(findings)}ê°œ\")\n",
        "\n",
        "    try:\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(\"\\n[ì—ì´ì „íŠ¸ì—ê²Œ ë³´ê³ ì„œ ì‘ì„± ìš”ì²­ ì¤‘...]\")\n",
        "\n",
        "        report_content = writer_agent.run(report_prompt)\n",
        "\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ì—ì´ì „íŠ¸ ë³´ê³ ì„œ ì‘ë‹µ - RAW]\\n{report_content[:500]}...(ì´í•˜ ìƒëµ)\")\n",
        "            progress_logs.append(f\"\\n[ë³´ê³ ì„œ ê¸¸ì´] {len(report_content)} ì\")\n",
        "\n",
        "        # í˜„ì¬ ì‹œê°„ ì¶”ê°€\n",
        "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        final_report = f\"ìƒì„± ì‹œê°„: {now}\\n\\n{report_content}\"\n",
        "\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(\"\\n[ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ]\")\n",
        "\n",
        "        return final_report\n",
        "    except Exception as e:\n",
        "        if progress_logs is not None:\n",
        "            progress_logs.append(f\"\\n[ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ] {str(e)}\\nê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±ìœ¼ë¡œ ì „í™˜\")\n",
        "\n",
        "        # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±\n",
        "        return generate_simple_report(query, findings, progress_logs)\n",
        "\n",
        "def generate_simple_report(query, findings, progress_logs=None):\n",
        "    \"\"\"\n",
        "    ê¸°ë³¸ì ì¸ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ìƒì„± (ì—ì´ì „íŠ¸ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ìš©)\n",
        "    \"\"\"\n",
        "    if progress_logs is not None:\n",
        "        progress_logs.append(\"\\n[ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„± ì‹œì‘]\")\n",
        "\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    report = f\"\"\"\n",
        "=== AI ë¦¬ì„œì¹˜ ë³´ê³ ì„œ: {query} ===\n",
        "ìƒì„± ì‹œê°„: {now}\n",
        "\n",
        "ğŸ” ê°œìš”:\n",
        "\"{query}\"ì— ëŒ€í•œ ìë™í™”ëœ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.\n",
        "ì´ ë³´ê³ ì„œëŠ” ë‹¤ì–‘í•œ ì˜¨ë¼ì¸ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­:\n",
        "\n",
        "\"\"\"\n",
        "    for i, finding in enumerate(findings, 1):\n",
        "        report += f\"{i}. {finding}\\n\\n\"\n",
        "\n",
        "    report += \"\"\"\n",
        "ğŸ’¡ ê²°ë¡ :\n",
        "ìœ„ ì •ë³´ëŠ” ìë™í™”ëœ ê²€ìƒ‰ì„ í†µí•´ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©°, ê° í•­ëª©ì˜ ì •í™•ì„±ê³¼ ìµœì‹ ì„±ì€ ì›ë³¸ ì¶œì²˜ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ì •ë³´ë¥¼ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ì˜ ê²€ì¦ì´ ê¶Œì¥ë©ë‹ˆë‹¤.\n",
        "\"\"\"\n",
        "\n",
        "    if progress_logs is not None:\n",
        "        progress_logs.append(f\"\\n[ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ] ê¸¸ì´: {len(report)} ì\")\n",
        "\n",
        "    return report\n",
        "\n",
        "def save_logs_to_file(logs, query, timestamp, search_results=None, expanded_queries=None, findings=None, report=None, agent_prompts=None):\n",
        "    \"\"\"ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "\n",
        "    sanitized_query = \"\".join(c for c in query if c.isalnum() or c in ' -_').strip().replace(' ', '_')[:30]\n",
        "    log_filename = f\"log_{sanitized_query}_{timestamp}.txt\"\n",
        "    log_path = os.path.join('logs', log_filename)\n",
        "\n",
        "    with open(log_path, 'w', encoding='utf-8') as f:\n",
        "        # í—¤ë” ì •ë³´\n",
        "        f.write(f\"=========================================================\\n\")\n",
        "        f.write(f\"===== ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì „ì²´ ë¡œê·¸: {query} =====\\n\")\n",
        "        f.write(f\"=========================================================\\n\")\n",
        "        f.write(f\"ì‹œì‘ ì‹œê°„: {datetime.fromtimestamp(int(timestamp.split('_')[0])).strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "\n",
        "        # ìƒì„¸ í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ (ëª¨ë“  ë‹¨ê³„ì™€ ê³¼ì • í¬í•¨)\n",
        "        f.write(\"=========================================================\\n\")\n",
        "        f.write(\"===== ì „ì²´ í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ (ëª¨ë“  ì¤‘ê°„ ë‹¨ê³„ í¬í•¨) =====\\n\")\n",
        "        f.write(\"=========================================================\\n\\n\")\n",
        "        f.write(\"\\n\".join(logs))\n",
        "\n",
        "        # êµ¬ë¶„ì„ \n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(\"=========================================================\\n\")\n",
        "        f.write(\"===== ìµœì¢… ê²°ê³¼ ìš”ì•½ =====\\n\")\n",
        "        f.write(\"=========================================================\\n\\n\")\n",
        "\n",
        "        # 1. ì¿¼ë¦¬ í™•ì¥ ë¡œê·¸\n",
        "        f.write(\"===== 1. ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼ =====\\n\")\n",
        "        if expanded_queries:\n",
        "            f.write(expanded_queries + \"\\n\\n\")\n",
        "\n",
        "        # 2. ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸\n",
        "        f.write(\"===== 2. ê²€ìƒ‰ ê²°ê³¼ (RAW) =====\\n\")\n",
        "        if search_results:\n",
        "            for i, result in enumerate(search_results):\n",
        "                f.write(f\"\\n--- ê²€ìƒ‰ {i+1}: \\\"{result['query']}\\\" ---\\n\")\n",
        "                f.write(result['result'])\n",
        "                f.write(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
        "\n",
        "        # 3. ë¶„ì„ ê²°ê³¼ ë¡œê·¸\n",
        "        f.write(\"\\n===== 3. ë¶„ì„ ê²°ê³¼ =====\\n\")\n",
        "        if findings:\n",
        "            f.write(findings + \"\\n\\n\")\n",
        "\n",
        "        # 4. ìµœì¢… ë³´ê³ ì„œ\n",
        "        f.write(\"===== 4. ìµœì¢… ë³´ê³ ì„œ =====\\n\")\n",
        "        if report:\n",
        "            f.write(report + \"\\n\\n\")\n",
        "\n",
        "    return log_path\n",
        "\n",
        "def process_query(query):\n",
        "    # ì—ì´ì „íŠ¸ë“¤ ìƒì„±\n",
        "    progress_logs = []  # ì§„í–‰ ìƒí™©ê³¼ ëª¨ë“  ì¤‘ê°„ ê³¼ì •ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    # ì‹œì‘ ë¡œê¹…\n",
        "    progress_logs.append(f\"==================================================\")\n",
        "    progress_logs.append(f\"===== ë©€í‹° ì—ì´ì „íŠ¸ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ =====\")\n",
        "    progress_logs.append(f\"==================================================\")\n",
        "    progress_logs.append(f\"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    progress_logs.append(f\"ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'\")\n",
        "\n",
        "    # ì—ì´ì „íŠ¸ ìƒì„± ë¡œê¹…\n",
        "    progress_logs.append(\"\\n[ì—ì´ì „íŠ¸ ìƒì„± ì‹œì‘]\")\n",
        "\n",
        "    search_agent = create_search_agent()\n",
        "    progress_logs.append(\"[ê²€ìƒ‰ ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ] DuckDuckGoSearchTool ì‚¬ìš©\")\n",
        "\n",
        "    analyzer_agent = create_analyzer_agent()\n",
        "    progress_logs.append(\"[ë¶„ì„ ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ] ë„êµ¬ ì—†ìŒ\")\n",
        "\n",
        "    writer_agent = create_writer_agent()\n",
        "    progress_logs.append(\"[ì‘ì„± ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ] CodeAgent ì‚¬ìš©\\n\")\n",
        "\n",
        "    # ì‹œì‘ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (íŒŒì¼ëª…ìš©)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ë° UI ë°˜í™˜ í•¨ìˆ˜\n",
        "    def update_ui(message=None, expanded=None, findings=None, report=None, file=None, log_file=None):\n",
        "        if message:\n",
        "            progress_logs.append(message)\n",
        "\n",
        "        return (\n",
        "            \"\\n\".join(progress_logs[-15:]),  # UIì—ëŠ” ìµœê·¼ 15ê°œ ë©”ì‹œì§€ë§Œ í‘œì‹œ\n",
        "            expanded if expanded is not None else \"\",\n",
        "            findings if findings is not None else \"\",\n",
        "            report if report is not None else \"\",\n",
        "            file,\n",
        "            log_file\n",
        "        )\n",
        "\n",
        "    # 1ë‹¨ê³„: ì¿¼ë¦¬ í™•ì¥\n",
        "    yield update_ui(\"1ï¸âƒ£ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ëŠ” ì¤‘...\")\n",
        "    progress_logs.append(f\"\\n[ì›ë³¸ ì¿¼ë¦¬] {query}\")\n",
        "\n",
        "    # ì¿¼ë¦¬ í™•ì¥ ê³¼ì •ì— ë¡œê·¸ ì „ë‹¬\n",
        "    expanded_queries = expand_query(analyzer_agent, query, progress_logs)\n",
        "    expanded_queries_text = \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(expanded_queries)])\n",
        "\n",
        "    yield update_ui(f\"âœ… ì¿¼ë¦¬ í™•ì¥ ì™„ë£Œ: {len(expanded_queries)}ê°œì˜ ê²€ìƒ‰ì–´ ìƒì„±ë¨\", expanded_queries_text)\n",
        "    for i, eq in enumerate(expanded_queries, 1):\n",
        "        yield update_ui(f\"   {i}. {eq}\", expanded_queries_text)\n",
        "\n",
        "    # 2ë‹¨ê³„: í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ìˆ˜í–‰\n",
        "    yield update_ui(\"\\n2ï¸âƒ£ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì¤‘...\", expanded_queries_text)\n",
        "    progress_logs.append(\"\\n==== ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ====\")\n",
        "\n",
        "    search_results = []\n",
        "    for i, expanded_query in enumerate(expanded_queries, 1):\n",
        "        progress_logs.append(f\"\\n---- ê²€ìƒ‰ {i}/{len(expanded_queries)} ì‹œì‘ ----\")\n",
        "        progress_logs.append(f\"[ê²€ìƒ‰ ì¿¼ë¦¬] \\\"{expanded_query}\\\"\")\n",
        "\n",
        "        yield update_ui(f\"   â”” ê²€ìƒ‰ {i}/{len(expanded_queries)}: \\\"{expanded_query}\\\"\", expanded_queries_text)\n",
        "\n",
        "        # ê²€ìƒ‰ ì‹¤í–‰ ë° ë¡œê¹…\n",
        "        progress_logs.append(\"[ê²€ìƒ‰ ì—ì´ì „íŠ¸ì— ìš”ì²­ ì „ì†¡ ì¤‘...]\")\n",
        "        search_start_time = datetime.now()\n",
        "\n",
        "        try:\n",
        "            result = search_agent.run(expanded_query)\n",
        "            search_time = (datetime.now() - search_start_time).total_seconds()\n",
        "\n",
        "            # ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…\n",
        "            word_count = len(result.split())\n",
        "            char_count = len(result)\n",
        "            progress_logs.append(f\"[ê²€ìƒ‰ ì™„ë£Œ] ì†Œìš” ì‹œê°„: {search_time:.2f}ì´ˆ, ë‹¨ì–´ ìˆ˜: {word_count}, ë¬¸ì ìˆ˜: {char_count}\")\n",
        "            progress_logs.append(f\"[ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°] {result[:150]}...\")\n",
        "\n",
        "            search_results.append({\"query\": expanded_query, \"result\": result})\n",
        "\n",
        "            yield update_ui(f\"     â†³ ê²€ìƒ‰ ì™„ë£Œ ({word_count} ë‹¨ì–´, {char_count} ê¸€ì, {search_time:.1f}ì´ˆ ì†Œìš”)\", expanded_queries_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            progress_logs.append(f\"[ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ] {str(e)}\")\n",
        "            yield update_ui(f\"     â†³ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", expanded_queries_text)\n",
        "\n",
        "        progress_logs.append(f\"---- ê²€ìƒ‰ {i}/{len(expanded_queries)} ì™„ë£Œ ----\")\n",
        "\n",
        "    progress_logs.append(\"\\n==== ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ====\")\n",
        "\n",
        "    # 3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n",
        "    yield update_ui(\"\\n3ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...\", expanded_queries_text)\n",
        "\n",
        "    # ë¶„ì„ ê³¼ì •ì— ë¡œê·¸ ì „ë‹¬\n",
        "    key_findings = analyze_results(analyzer_agent, search_results, progress_logs)\n",
        "    findings_text = \"\\n\".join([f\"{i+1}. {finding}\" for i, finding in enumerate(key_findings)])\n",
        "\n",
        "    yield update_ui(f\"âœ… ë¶„ì„ ì™„ë£Œ. {len(key_findings)}ê°œì˜ í•µì‹¬ ë°œê²¬ì‚¬í•­ ì¶”ì¶œë¨.\", expanded_queries_text, findings_text)\n",
        "\n",
        "    # 4ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥\n",
        "    yield update_ui(\"\\n4ï¸âƒ£ ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\", expanded_queries_text, findings_text)\n",
        "\n",
        "    # ë³´ê³ ì„œ ìƒì„± ê³¼ì •ì— ë¡œê·¸ ì „ë‹¬\n",
        "    report = generate_report(writer_agent, query, key_findings, expanded_queries_text, progress_logs)\n",
        "\n",
        "    # reports ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "    progress_logs.append(\"\\n[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] 'reports' ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...\")\n",
        "    os.makedirs('reports', exist_ok=True)\n",
        "    progress_logs.append(\"[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ\")\n",
        "\n",
        "    # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€\n",
        "    sanitized_query = \"\".join(c for c in query if c.isalnum() or c in ' -_').strip().replace(' ', '_')[:30]\n",
        "    filename = f\"report_{sanitized_query}_{timestamp}.txt\"\n",
        "    report_path = os.path.join('reports', filename)\n",
        "\n",
        "    progress_logs.append(f\"[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] ë³´ê³ ì„œ ì €ì¥ ì¤€ë¹„ ì¤‘: '{report_path}'\")\n",
        "\n",
        "    # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥\n",
        "    with open(report_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(report)\n",
        "\n",
        "    progress_logs.append(f\"[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {len(report)} ì\")\n",
        "\n",
        "    # ë¡œê·¸ ì €ì¥ ë§ˆë¬´ë¦¬\n",
        "    progress_logs.append(\"\\n==== í”„ë¡œì„¸ìŠ¤ ë§ˆë¬´ë¦¬ ====\")\n",
        "    progress_logs.append(f\"[ì‘ì—… ì™„ë£Œ ì‹œê°„] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    progress_logs.append(f\"[ì´ ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´] {len(expanded_queries)}ê°œ\")\n",
        "    progress_logs.append(f\"[ì´ ë°œê²¬ëœ ì •ë³´] {len(key_findings)}ê°œ\")\n",
        "    progress_logs.append(f\"[ìµœì¢… ë³´ê³ ì„œ í¬ê¸°] {len(report)} ì\")\n",
        "\n",
        "    # ë¡œê·¸ íŒŒì¼ ì €ì¥ (ëª¨ë“  raw ë°ì´í„° ë° ì¤‘ê°„ ê³¼ì • í¬í•¨)\n",
        "    log_path = save_logs_to_file(\n",
        "        progress_logs,\n",
        "        query,\n",
        "        timestamp,\n",
        "        search_results=search_results,\n",
        "        expanded_queries=expanded_queries_text,\n",
        "        findings=findings_text,\n",
        "        report=report\n",
        "    )\n",
        "\n",
        "    yield update_ui(\"\\nâœ¨ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\", expanded_queries_text, findings_text, report, report_path, log_path)\n",
        "    yield update_ui(f\"ğŸ“„ ë³´ê³ ì„œê°€ '{report_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\", expanded_queries_text, findings_text, report, report_path, log_path)\n",
        "    yield update_ui(f\"ğŸ“‹ ì „ì²´ ê³¼ì • ìƒì„¸ ë¡œê·¸ê°€ '{log_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\", expanded_queries_text, findings_text, report, report_path, log_path)\n",
        "\n",
        "    # ìµœì¢… ê²°ê³¼ ë°˜í™˜\n",
        "    return (\n",
        "        \"\\n\".join(progress_logs[-15:]),  # UIì—ëŠ” ìµœê·¼ 15ê°œ ë©”ì‹œì§€ë§Œ í‘œì‹œ\n",
        "        expanded_queries_text,\n",
        "        findings_text,\n",
        "        report,\n",
        "        report_path,\n",
        "        log_path\n",
        "    )\n",
        "\n",
        "def create_gradio_interface():\n",
        "    with gr.Blocks(title=\"ë©€í‹° ì—ì´ì „íŠ¸ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ\", theme=gr.themes.Soft()) as interface:\n",
        "        gr.Markdown(\"# ğŸ¤– ë©€í‹° ì—ì´ì „íŠ¸ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ\")\n",
        "        gr.Markdown(\"ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´, AI ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ë ¥í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # ì…ë ¥\n",
        "                query_input = gr.Textbox(\n",
        "                    label=\"ê²€ìƒ‰ ì£¼ì œ\",\n",
        "                    placeholder=\"ì˜ˆ: ë²šê½ƒ ê°œí™”ì‹œê¸°\",\n",
        "                    lines=2\n",
        "                )\n",
        "                search_button = gr.Button(\"ğŸ” ê²€ìƒ‰ ì‹œì‘\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                # ì§„í–‰ ìƒí™©\n",
        "                progress_output = gr.Textbox(\n",
        "                    label=\"ì§„í–‰ ìƒí™©\",\n",
        "                    lines=15,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                # í™•ì¥ëœ ì¿¼ë¦¬\n",
        "                expanded_queries_output = gr.Textbox(\n",
        "                    label=\"í™•ì¥ëœ ê²€ìƒ‰ì–´\",\n",
        "                    lines=5,\n",
        "                    interactive=False\n",
        "                )\n",
        "                # ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
        "                findings_output = gr.Textbox(\n",
        "                    label=\"ì£¼ìš” ë°œê²¬ì‚¬í•­\",\n",
        "                    lines=10,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "            with gr.Column():\n",
        "                # ìµœì¢… ë³´ê³ ì„œ\n",
        "                report_output = gr.Textbox(\n",
        "                    label=\"ìµœì¢… ë³´ê³ ì„œ\",\n",
        "                    lines=20,\n",
        "                    interactive=False\n",
        "                )\n",
        "                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "                with gr.Row():\n",
        "                    # ë³´ê³ ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "                    file_output = gr.File(\n",
        "                        label=\"ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ\",\n",
        "                        interactive=False\n",
        "                    )\n",
        "                    # ë¡œê·¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "                    log_file_output = gr.File(\n",
        "                        label=\"ë¡œê·¸ ë‹¤ìš´ë¡œë“œ\",\n",
        "                        interactive=False\n",
        "                    )\n",
        "\n",
        "        # ì´ë²¤íŠ¸ ì—°ê²°\n",
        "        search_button.click(\n",
        "            fn=process_query,\n",
        "            inputs=query_input,\n",
        "            outputs=[\n",
        "                progress_output,\n",
        "                expanded_queries_output,\n",
        "                findings_output,\n",
        "                report_output,\n",
        "                file_output,\n",
        "                log_file_output\n",
        "            ],\n",
        "            show_progress=False\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interface = create_gradio_interface()\n",
        "    # interface.launch() ëŒ€ì‹  ì•„ë˜ ì½”ë“œ ì‚¬ìš©\n",
        "    interface.queue().launch(\n",
        "        server_name=\"0.0.0.0\",\n",
        "        share=True,\n",
        "        show_error=True,\n",
        "        prevent_thread_lock=True  # ì´ ì˜µì…˜ì´ ì¤‘ìš”í•©ë‹ˆë‹¤!\n",
        "    )"
      ],
      "metadata": {
        "id": "5xIuPMrSoN_k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}