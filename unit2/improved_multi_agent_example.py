from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, HfApiModel, tools
import json
from datetime import datetime
import gradio as gr
import os

def create_search_agent():
    # ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸
    return ToolCallingAgent(
        tools=[DuckDuckGoSearchTool()],
        model=HfApiModel()
    )

def create_writer_agent():
    # íŒŒì¼ ì‘ì„±ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸
    return CodeAgent(
        tools=[],  # CodeAgentëŠ” ê¸°ë³¸ì ìœ¼ë¡œ íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤
        model=HfApiModel()
    )

def create_analyzer_agent():
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì •ë¦¬í•˜ëŠ” ì—ì´ì „íŠ¸
    return ToolCallingAgent(
        tools=[],  # ë¶„ì„ ì—ì´ì „íŠ¸ëŠ” íŠ¹ë³„í•œ ë„êµ¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        model=HfApiModel()
    )

def expand_query(agent, original_query, progress_logs=None):
    # ì›ë³¸ ì¿¼ë¦¬ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì„¸ë¶€ ì¿¼ë¦¬ë¡œ í™•ì¥
    expansion_prompt = f"""
    ë‹¤ìŒ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ëœ 4ê°œì˜ êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
    ê°ê°ì˜ ì¿¼ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´ì´ë‚˜ ê´€ì ì„ ë‹¤ë¤„ì•¼ í•˜ë©°, ì‹¤ì œ ê²€ìƒ‰ì— íš¨ê³¼ì ì¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
    
    ê²€ìƒ‰ì–´: {original_query}
    
    ì‘ë‹µ í˜•ì‹:
    1. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
    2. ê° ì¿¼ë¦¬ëŠ” ê²€ìƒ‰ ì—”ì§„ì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    3. ì¿¼ë¦¬ëŠ” í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {{
        "queries": [
            "êµ¬ì²´ì ì¸ ì²« ë²ˆì§¸ ê²€ìƒ‰ì–´",
            "êµ¬ì²´ì ì¸ ë‘ ë²ˆì§¸ ê²€ìƒ‰ì–´",
            "êµ¬ì²´ì ì¸ ì„¸ ë²ˆì§¸ ê²€ìƒ‰ì–´",
            "êµ¬ì²´ì ì¸ ë„¤ ë²ˆì§¸ ê²€ìƒ‰ì–´"
        ]
    }}
    """
    
    if progress_logs is not None:
        progress_logs.append("\n==== ì¿¼ë¦¬ í™•ì¥ í”„ë¡œì„¸ìŠ¤ ====")
        progress_logs.append(f"[í™•ì¥ ìš”ì²­ í”„ë¡¬í”„íŠ¸]\n{expansion_prompt}")
    
    try:
        # ì—ì´ì „íŠ¸ ì‘ë‹µ ë°›ê¸°
        if progress_logs is not None:
            progress_logs.append("\n[ì—ì´ì „íŠ¸ì—ê²Œ ì¿¼ë¦¬ í™•ì¥ ìš”ì²­ ì¤‘...]")
        
        result = agent.run(expansion_prompt)
        
        if progress_logs is not None:
            progress_logs.append(f"\n[ì—ì´ì „íŠ¸ ì‘ë‹µ - RAW]\n{result}")
            progress_logs.append("\n[JSON íŒŒì‹± ì‹œë„ ì¤‘...]")
        
        parsed_result = json.loads(result)
        
        if "queries" not in parsed_result or not parsed_result["queries"]:
            if progress_logs is not None:
                progress_logs.append("\n[ì˜¤ë¥˜] JSONì— 'queries' í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©.")
            return [original_query]
        
        queries = parsed_result["queries"]
        if progress_logs is not None:
            progress_logs.append(f"\n[ì¶”ì¶œëœ ì¿¼ë¦¬ - í•„í„°ë§ ì „]\n{json.dumps(queries, ensure_ascii=False, indent=2)}")
        
        # ë¹ˆ ì¿¼ë¦¬ë‚˜ ë„ˆë¬´ ì§§ì€ ì¿¼ë¦¬ í•„í„°ë§
        queries = [q for q in queries if q and len(q) > 2]
        
        if progress_logs is not None:
            progress_logs.append(f"\n[í•„í„°ë§ í›„ ì¿¼ë¦¬]\n{json.dumps(queries, ensure_ascii=False, indent=2)}")
        
        if not queries:
            if progress_logs is not None:
                progress_logs.append("\n[í•„í„°ë§ í›„ ìœ íš¨í•œ ì¿¼ë¦¬ ì—†ìŒ] ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©.")
            return [original_query]
        
        return queries
        
    except Exception as e:
        if progress_logs is not None:
            progress_logs.append(f"\n[ì¿¼ë¦¬ í™•ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ] {str(e)}\nì›ë³¸ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return [original_query]

def analyze_results(agent, search_results, progress_logs=None):
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìœ ìš©í•œ ì •ë³´ë§Œ ì¶”ì¶œ
    analysis_prompt = f"""
    ì•„ë˜ ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ê³  ê°€ì¥ ì¤‘ìš”í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    
    ë¶„ì„ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
    1. ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ë°˜ë³µë˜ëŠ” ì •ë³´ëŠ” ì‹ ë¢°ì„±ì´ ë†’ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
    2. ìµœì‹  ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.
    3. ì¶œì²˜ê°€ ëª…í™•í•œ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.
    4. ê° ë°œê²¬ì‚¬í•­ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ë‹´ì•„ì•¼ í•©ë‹ˆë‹¤.
    5. ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì œì™¸í•˜ì„¸ìš”.
    
    ê²€ìƒ‰ ê²°ê³¼:
    {json.dumps(search_results, indent=2, ensure_ascii=False)[:100000]}  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì‚¬ìš©
    
    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {{
        "key_findings": [
            {{
                "content": "ì²« ë²ˆì§¸ ë°œê²¬ì‚¬í•­ì˜ ìƒì„¸ ë‚´ìš©",
                "reliability": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ",
                "source": "ë°œê²¬ëœ ì¶œì²˜ (ì•Œ ìˆ˜ ìˆëŠ” ê²½ìš°)"
            }},
            {{
                "content": "ë‘ ë²ˆì§¸ ë°œê²¬ì‚¬í•­ì˜ ìƒì„¸ ë‚´ìš©",
                "reliability": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ",
                "source": "ë°œê²¬ëœ ì¶œì²˜ (ì•Œ ìˆ˜ ìˆëŠ” ê²½ìš°)"
            }},
            ...ê³„ì†...
        ]
    }}
    """
    
    if progress_logs is not None:
        progress_logs.append("\n==== ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ====")
        progress_logs.append("[ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸ - í—¤ë”ë§Œ í‘œì‹œ (ì „ì²´ ê¸¸ì´ê°€ ë„ˆë¬´ ê¹€)]\n" + analysis_prompt.split("ê²€ìƒ‰ ê²°ê³¼:")[0])
        progress_logs.append(f"\n[ë¶„ì„í•  ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜] {len(search_results)}ê°œ")
    
    try:
        # ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì‹œë„
        if progress_logs is not None:
            progress_logs.append("\n[ì—ì´ì „íŠ¸ì—ê²Œ ë¶„ì„ ìš”ì²­ ì¤‘...]")
        
        result = agent.run(analysis_prompt)
        
        if progress_logs is not None:
            progress_logs.append(f"\n[ì—ì´ì „íŠ¸ ë¶„ì„ ì‘ë‹µ - RAW]\n{result}")
            progress_logs.append("\n[JSON íŒŒì‹± ì‹œë„ ì¤‘...]")
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            parsed_result = json.loads(result)
            
            if progress_logs is not None:
                progress_logs.append(f"\n[JSON íŒŒì‹± ì„±ê³µ]\n{json.dumps(parsed_result, ensure_ascii=False, indent=2)[:1000]}...")
            
            if "key_findings" in parsed_result and parsed_result["key_findings"]:
                # JSON êµ¬ì¡°ê°€ ì˜ˆìƒëŒ€ë¡œì¸ ê²½ìš°
                if progress_logs is not None:
                    progress_logs.append("\n[ì˜ˆìƒ JSON êµ¬ì¡° í™•ì¸ë¨] 'key_findings' í‚¤ ìˆìŒ")
                
                findings = []
                for item in parsed_result["key_findings"]:
                    if isinstance(item, dict) and "content" in item:
                        # ì‹ ë¢°ë„ ì •ë³´ ì¶”ê°€
                        reliability = item.get("reliability", "")
                        source = item.get("source", "")
                        
                        content = item["content"]
                        if reliability and source:
                            findings.append(f"{content} (ì‹ ë¢°ë„: {reliability}, ì¶œì²˜: {source})")
                        elif reliability:
                            findings.append(f"{content} (ì‹ ë¢°ë„: {reliability})")
                        elif source:
                            findings.append(f"{content} (ì¶œì²˜: {source})")
                        else:
                            findings.append(content)
                    elif isinstance(item, str) and item:
                        findings.append(item)
                
                if progress_logs is not None:
                    progress_logs.append(f"\n[ì²˜ë¦¬ëœ ë°œê²¬ì‚¬í•­] {len(findings)}ê°œ í•­ëª© ì¶”ì¶œë¨")
                
                if findings:
                    return findings
            elif "key_findings" in parsed_result and isinstance(parsed_result["key_findings"], list):
                # ë‹¨ìˆœ ë¬¸ìì—´ ëª©ë¡ì¸ ê²½ìš°
                if progress_logs is not None:
                    progress_logs.append("\n[ë‹¨ìˆœ ëª©ë¡ êµ¬ì¡° í™•ì¸ë¨] ë¬¸ìì—´ ëª©ë¡ ì²˜ë¦¬ ì¤‘")
                
                findings = [item for item in parsed_result["key_findings"] if item and len(str(item)) > 10]
                
                if progress_logs is not None:
                    progress_logs.append(f"\n[í•„í„°ë§ í›„ ë°œê²¬ì‚¬í•­] {len(findings)}ê°œ í•­ëª© ì¶”ì¶œë¨")
                
                if findings:
                    return findings
            else:
                if progress_logs is not None:
                    progress_logs.append("\n[ì˜ˆìƒê³¼ ë‹¤ë¥¸ JSON êµ¬ì¡°] 'key_findings' í‚¤ê°€ ì—†ê±°ë‚˜ ë‹¤ë¥¸ í˜•ì‹")
        
        except json.JSONDecodeError:
            # JSON íŒŒì‹±ì— ì‹¤íŒ¨í•œ ê²½ìš°, ì¤„ ë‹¨ìœ„ë¡œ ì˜ë¯¸ ìˆëŠ” ì •ë³´ ì¶”ì¶œ ì‹œë„
            if progress_logs is not None:
                progress_logs.append("\n[JSON íŒŒì‹± ì‹¤íŒ¨] í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ì „í™˜")
        
        # JSON íŒŒì‹±ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì˜ˆìƒ êµ¬ì¡°ê°€ ì•„ë‹Œ ê²½ìš°, í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œë„
        if progress_logs is not None:
            progress_logs.append("\n[í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ì‹œì‘] ì¤„ ë‹¨ìœ„ ë¶„ì„")
        
        lines = result.split("\n")
        findings = []
        for line in lines:
            line = line.strip()
            # ì˜ë¯¸ ìˆëŠ” ì¤„ë§Œ ì¶”ì¶œ (ì§§ì€ ì¤„, JSON í‘œê¸°, ë¹ˆ ì¤„ ì œì™¸)
            if line and len(line) > 30 and not (line.startswith('{') or line.startswith('}') or line.startswith('[') or line.startswith(']')):
                findings.append(line)
        
        if progress_logs is not None:
            progress_logs.append(f"\n[í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼] {len(findings)}ê°œ ì˜ë¯¸ ìˆëŠ” ì¤„ ì¶”ì¶œë¨")
        
        if findings:
            return findings
            
        # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜
        if progress_logs is not None:
            progress_logs.append("\n[ë¶„ì„ ì‹¤íŒ¨] ëª¨ë“  ë¶„ì„ ë°©ë²• ì‹¤íŒ¨. ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜")
        
        return ["ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì‹œë„í•´ë³´ì„¸ìš”."]
            
    except Exception as e:
        if progress_logs is not None:
            progress_logs.append(f"\n[ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ] {str(e)}")
        
        return [f"ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"]

def generate_report(writer_agent, query, findings, expanded_queries, progress_logs=None):
    """
    ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” í’ë¶€í•œ ë³´ê³ ì„œ ìƒì„±
    """
    report_prompt = f"""
    ë‹¤ìŒ ì£¼ì œì™€ ë°œê²¬ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

    ì£¼ì œ: {query}

    ì¡°ì‚¬ì— ì‚¬ìš©ëœ ê²€ìƒ‰ì–´:
    {expanded_queries}

    ë°œê²¬ëœ ì£¼ìš” ì •ë³´:
    {chr(10).join([f"- {finding}" for finding in findings])}

    ë³´ê³ ì„œëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:
    1. ì œëª©: ì£¼ì œë¥¼ ì˜ ë‚˜íƒ€ë‚´ëŠ” ëª…í™•í•œ ì œëª© (êµµì€ ê¸€ì”¨)
    2. ê°œìš”: ì£¼ì œì— ëŒ€í•œ ì†Œê°œì™€ ì¡°ì‚¬ì˜ ë°°ê²½ ë° ëª©ì  (ìµœì†Œ 200ì ì´ìƒ)
    3. ì£¼ìš” ë°œê²¬ì‚¬í•­: ê°€ì¥ ì¤‘ìš”í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë¥¼ ìƒì„¸íˆ ì„¤ëª… (ê° í•­ëª©ë‹¹ ìµœì†Œ 200ì ì´ìƒ, ì´ 5ê°œ ì´ìƒì˜ í•­ëª©)
    4. ì„¸ë¶€ ë¶„ì„:
       a. ì •ë³´ì˜ ì‹ ë¢°ì„± í‰ê°€ (ì†ŒìŠ¤ ë¶„ì„, êµì°¨ ê²€ì¦ ê²°ê³¼)
       b. ë°œê²¬ëœ ìŸì ì´ë‚˜ ë…¼ë€ (ìˆëŠ” ê²½ìš°)
       c. ì‹œê°„ì  ë³€í™”ë‚˜ ì¶”ì„¸ (ê´€ë ¨ì´ ìˆëŠ” ê²½ìš°)
       d. ì§€ì—­ì /ë¬¸í™”ì  ì°¨ì´ì  (ê´€ë ¨ì´ ìˆëŠ” ê²½ìš°)
    5. í†µí•©ì  ë¶„ì„: ëª¨ë“  ë°œê²¬ì‚¬í•­ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ì‹¬ì¸µ í•´ì„ (ìµœì†Œ 500ì ì´ìƒ)
    6. ê²°ë¡  ë° ì œì–¸: ì „ì²´ ë‚´ìš©ì˜ ìš”ì•½ê³¼ í–¥í›„ ì£¼ëª©í•  ì  ë˜ëŠ” ê¶Œì¥ì‚¬í•­ (ìµœì†Œ 400ì ì´ìƒ)
    7. ì´ ë³´ê³ ì„œì˜ í•œê³„: ì •ë³´ ìˆ˜ì§‘ ê³¼ì •ì˜ ì œí•œì‚¬í•­ì´ë‚˜ í–¥í›„ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•œ ë¶€ë¶„
    
    ë³´ê³ ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­:
    - ê° ì„¹ì…˜ë§ˆë‹¤ ì¶©ë¶„í•œ ë‚´ìš©ê³¼ ê¹Šì´ë¥¼ í¬í•¨í•  ê²ƒ (ì „ì²´ ë³´ê³ ì„œëŠ” ìµœì†Œ 5000ì ì´ìƒ)
    - ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ ì‚¬ì‹¤ë“¤ì„ ì—°ê²°í•˜ê³  í•´ì„í•˜ëŠ” í†µí•©ì  ë¶„ì„ì„ ì œê³µí•  ê²ƒ
    - ê°€ëŠ¥í•œ ê²½ìš° ì¶œì²˜ì™€ ë‚ ì§œë¥¼ í¬í•¨í•  ê²ƒ
    - ì „ë¬¸ ìš©ì–´ê°€ ìˆë‹¤ë©´ ê°„ëµíˆ ì„¤ëª…í•  ê²ƒ
    - ê°ê´€ì ì´ê³  ê· í˜• ì¡íŒ ê´€ì ì—ì„œ ì„œìˆ í•  ê²ƒ
    """
    
    if progress_logs is not None:
        progress_logs.append("\n==== ë³´ê³ ì„œ ìƒì„± í”„ë¡œì„¸ìŠ¤ ====")
        progress_logs.append("[ë³´ê³ ì„œ ì‘ì„± ìš”ì²­ í”„ë¡¬í”„íŠ¸]\n" + report_prompt.split("ë°œê²¬ëœ ì£¼ìš” ì •ë³´:")[0] + "ë°œê²¬ëœ ì£¼ìš” ì •ë³´: [...]")
        progress_logs.append(f"\n[ì²˜ë¦¬í•  ë°œê²¬ì‚¬í•­ ìˆ˜] {len(findings)}ê°œ")
    
    try:
        if progress_logs is not None:
            progress_logs.append("\n[ì—ì´ì „íŠ¸ì—ê²Œ ë³´ê³ ì„œ ì‘ì„± ìš”ì²­ ì¤‘...]")
        
        report_content = writer_agent.run(report_prompt)
        
        if progress_logs is not None:
            progress_logs.append(f"\n[ì—ì´ì „íŠ¸ ë³´ê³ ì„œ ì‘ë‹µ - RAW]\n{report_content[:500]}...(ì´í•˜ ìƒëµ)")
            progress_logs.append(f"\n[ë³´ê³ ì„œ ê¸¸ì´] {len(report_content)} ì")
        
        # í˜„ì¬ ì‹œê°„ ì¶”ê°€
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        final_report = f"ìƒì„± ì‹œê°„: {now}\n\n{report_content}"
        
        if progress_logs is not None:
            progress_logs.append("\n[ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ]")
        
        return final_report
    except Exception as e:
        if progress_logs is not None:
            progress_logs.append(f"\n[ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ] {str(e)}\nê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±ìœ¼ë¡œ ì „í™˜")
        
        # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±
        return generate_simple_report(query, findings, progress_logs)

def generate_simple_report(query, findings, progress_logs=None):
    """
    ê¸°ë³¸ì ì¸ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ìƒì„± (ì—ì´ì „íŠ¸ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ìš©)
    """
    if progress_logs is not None:
        progress_logs.append("\n[ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„± ì‹œì‘]")
    
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report = f"""
=== AI ë¦¬ì„œì¹˜ ë³´ê³ ì„œ: {query} ===
ìƒì„± ì‹œê°„: {now}

ğŸ” ê°œìš”:
"{query}"ì— ëŒ€í•œ ìë™í™”ëœ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.
ì´ ë³´ê³ ì„œëŠ” ë‹¤ì–‘í•œ ì˜¨ë¼ì¸ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.

ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­:

"""
    for i, finding in enumerate(findings, 1):
        report += f"{i}. {finding}\n\n"
    
    report += """
ğŸ’¡ ê²°ë¡ :
ìœ„ ì •ë³´ëŠ” ìë™í™”ëœ ê²€ìƒ‰ì„ í†µí•´ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©°, ê° í•­ëª©ì˜ ì •í™•ì„±ê³¼ ìµœì‹ ì„±ì€ ì›ë³¸ ì¶œì²˜ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ì •ë³´ë¥¼ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ì˜ ê²€ì¦ì´ ê¶Œì¥ë©ë‹ˆë‹¤.
"""
    
    if progress_logs is not None:
        progress_logs.append(f"\n[ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ] ê¸¸ì´: {len(report)} ì")
    
    return report

def save_logs_to_file(logs, query, timestamp, search_results=None, expanded_queries=None, findings=None, report=None, agent_prompts=None):
    """ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    os.makedirs('logs', exist_ok=True)
    
    sanitized_query = "".join(c for c in query if c.isalnum() or c in ' -_').strip().replace(' ', '_')[:30]
    log_filename = f"log_{sanitized_query}_{timestamp}.txt"
    log_path = os.path.join('logs', log_filename)
    
    with open(log_path, 'w', encoding='utf-8') as f:
        # í—¤ë” ì •ë³´
        f.write(f"=========================================================\n")
        f.write(f"===== ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì „ì²´ ë¡œê·¸: {query} =====\n")
        f.write(f"=========================================================\n")
        f.write(f"ì‹œì‘ ì‹œê°„: {datetime.fromtimestamp(int(timestamp.split('_')[0])).strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # ìƒì„¸ í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ (ëª¨ë“  ë‹¨ê³„ì™€ ê³¼ì • í¬í•¨)
        f.write("=========================================================\n")
        f.write("===== ì „ì²´ í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ (ëª¨ë“  ì¤‘ê°„ ë‹¨ê³„ í¬í•¨) =====\n")
        f.write("=========================================================\n\n")
        f.write("\n".join(logs))
        
        # êµ¬ë¶„ì„ 
        f.write("\n\n")
        f.write("=========================================================\n")
        f.write("===== ìµœì¢… ê²°ê³¼ ìš”ì•½ =====\n")
        f.write("=========================================================\n\n")
        
        # 1. ì¿¼ë¦¬ í™•ì¥ ë¡œê·¸
        f.write("===== 1. ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼ =====\n")
        if expanded_queries:
            f.write(expanded_queries + "\n\n")
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸
        f.write("===== 2. ê²€ìƒ‰ ê²°ê³¼ (RAW) =====\n")
        if search_results:
            for i, result in enumerate(search_results):
                f.write(f"\n--- ê²€ìƒ‰ {i+1}: \"{result['query']}\" ---\n")
                f.write(result['result'])
                f.write("\n" + "-" * 80 + "\n")
        
        # 3. ë¶„ì„ ê²°ê³¼ ë¡œê·¸
        f.write("\n===== 3. ë¶„ì„ ê²°ê³¼ =====\n")
        if findings:
            f.write(findings + "\n\n")
        
        # 4. ìµœì¢… ë³´ê³ ì„œ
        f.write("===== 4. ìµœì¢… ë³´ê³ ì„œ =====\n")
        if report:
            f.write(report + "\n\n")
    
    return log_path

def process_query(query):
    # ì—ì´ì „íŠ¸ë“¤ ìƒì„±
    progress_logs = []  # ì§„í–‰ ìƒí™©ê³¼ ëª¨ë“  ì¤‘ê°„ ê³¼ì •ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    
    # ì‹œì‘ ë¡œê¹…
    progress_logs.append(f"==================================================")
    progress_logs.append(f"===== ë©€í‹° ì—ì´ì „íŠ¸ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ =====")
    progress_logs.append(f"==================================================")
    progress_logs.append(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    progress_logs.append(f"ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
    
    # ì—ì´ì „íŠ¸ ìƒì„± ë¡œê¹…
    progress_logs.append("\n[ì—ì´ì „íŠ¸ ìƒì„± ì‹œì‘]")
    
    search_agent = create_search_agent()
    progress_logs.append("[ê²€ìƒ‰ ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ] DuckDuckGoSearchTool ì‚¬ìš©")
    
    analyzer_agent = create_analyzer_agent()
    progress_logs.append("[ë¶„ì„ ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ] ë„êµ¬ ì—†ìŒ")
    
    writer_agent = create_writer_agent()
    progress_logs.append("[ì‘ì„± ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ] CodeAgent ì‚¬ìš©\n")
    
    # ì‹œì‘ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (íŒŒì¼ëª…ìš©)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ë° UI ë°˜í™˜ í•¨ìˆ˜
    def update_ui(message=None, expanded=None, findings=None, report=None, file=None, log_file=None):
        if message:
            progress_logs.append(message)
        
        return (
            "\n".join(progress_logs[-15:]),  # UIì—ëŠ” ìµœê·¼ 15ê°œ ë©”ì‹œì§€ë§Œ í‘œì‹œ
            expanded if expanded is not None else "",
            findings if findings is not None else "",
            report if report is not None else "",
            file,
            log_file
        )
    
    # 1ë‹¨ê³„: ì¿¼ë¦¬ í™•ì¥
    yield update_ui("1ï¸âƒ£ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ëŠ” ì¤‘...")
    progress_logs.append(f"\n[ì›ë³¸ ì¿¼ë¦¬] {query}")
    
    # ì¿¼ë¦¬ í™•ì¥ ê³¼ì •ì— ë¡œê·¸ ì „ë‹¬
    expanded_queries = expand_query(analyzer_agent, query, progress_logs)
    expanded_queries_text = "\n".join([f"{i+1}. {q}" for i, q in enumerate(expanded_queries)])
    
    yield update_ui(f"âœ… ì¿¼ë¦¬ í™•ì¥ ì™„ë£Œ: {len(expanded_queries)}ê°œì˜ ê²€ìƒ‰ì–´ ìƒì„±ë¨", expanded_queries_text)
    for i, eq in enumerate(expanded_queries, 1):
        yield update_ui(f"   {i}. {eq}", expanded_queries_text)
    
    # 2ë‹¨ê³„: í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    yield update_ui("\n2ï¸âƒ£ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì¤‘...", expanded_queries_text)
    progress_logs.append("\n==== ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ====")
    
    search_results = []
    for i, expanded_query in enumerate(expanded_queries, 1):
        progress_logs.append(f"\n---- ê²€ìƒ‰ {i}/{len(expanded_queries)} ì‹œì‘ ----")
        progress_logs.append(f"[ê²€ìƒ‰ ì¿¼ë¦¬] \"{expanded_query}\"")
        
        yield update_ui(f"   â”” ê²€ìƒ‰ {i}/{len(expanded_queries)}: \"{expanded_query}\"", expanded_queries_text)
        
        # ê²€ìƒ‰ ì‹¤í–‰ ë° ë¡œê¹…
        progress_logs.append("[ê²€ìƒ‰ ì—ì´ì „íŠ¸ì— ìš”ì²­ ì „ì†¡ ì¤‘...]")
        search_start_time = datetime.now()
        
        try:
            result = search_agent.run(expanded_query)
            search_time = (datetime.now() - search_start_time).total_seconds()
            
            # ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
            word_count = len(result.split())
            char_count = len(result)
            progress_logs.append(f"[ê²€ìƒ‰ ì™„ë£Œ] ì†Œìš” ì‹œê°„: {search_time:.2f}ì´ˆ, ë‹¨ì–´ ìˆ˜: {word_count}, ë¬¸ì ìˆ˜: {char_count}")
            progress_logs.append(f"[ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°] {result[:150]}...")
            
            search_results.append({"query": expanded_query, "result": result})
            
            yield update_ui(f"     â†³ ê²€ìƒ‰ ì™„ë£Œ ({word_count} ë‹¨ì–´, {char_count} ê¸€ì, {search_time:.1f}ì´ˆ ì†Œìš”)", expanded_queries_text)
            
        except Exception as e:
            progress_logs.append(f"[ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ] {str(e)}")
            yield update_ui(f"     â†³ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", expanded_queries_text)
        
        progress_logs.append(f"---- ê²€ìƒ‰ {i}/{len(expanded_queries)} ì™„ë£Œ ----")
    
    progress_logs.append("\n==== ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ====")
    
    # 3ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
    yield update_ui("\n3ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...", expanded_queries_text)
    
    # ë¶„ì„ ê³¼ì •ì— ë¡œê·¸ ì „ë‹¬
    key_findings = analyze_results(analyzer_agent, search_results, progress_logs)
    findings_text = "\n".join([f"{i+1}. {finding}" for i, finding in enumerate(key_findings)])
    
    yield update_ui(f"âœ… ë¶„ì„ ì™„ë£Œ. {len(key_findings)}ê°œì˜ í•µì‹¬ ë°œê²¬ì‚¬í•­ ì¶”ì¶œë¨.", expanded_queries_text, findings_text)
    
    # 4ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥
    yield update_ui("\n4ï¸âƒ£ ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...", expanded_queries_text, findings_text)
    
    # ë³´ê³ ì„œ ìƒì„± ê³¼ì •ì— ë¡œê·¸ ì „ë‹¬
    report = generate_report(writer_agent, query, key_findings, expanded_queries_text, progress_logs)
    
    # reports ë””ë ‰í† ë¦¬ ìƒì„±
    progress_logs.append("\n[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] 'reports' ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...")
    os.makedirs('reports', exist_ok=True)
    progress_logs.append("[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ")
    
    # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
    sanitized_query = "".join(c for c in query if c.isalnum() or c in ' -_').strip().replace(' ', '_')[:30]
    filename = f"report_{sanitized_query}_{timestamp}.txt"
    report_path = os.path.join('reports', filename)
    
    progress_logs.append(f"[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] ë³´ê³ ì„œ ì €ì¥ ì¤€ë¹„ ì¤‘: '{report_path}'")
    
    # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    progress_logs.append(f"[íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…] ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {len(report)} ì")
    
    # ë¡œê·¸ ì €ì¥ ë§ˆë¬´ë¦¬
    progress_logs.append("\n==== í”„ë¡œì„¸ìŠ¤ ë§ˆë¬´ë¦¬ ====")
    progress_logs.append(f"[ì‘ì—… ì™„ë£Œ ì‹œê°„] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    progress_logs.append(f"[ì´ ì²˜ë¦¬ëœ ê²€ìƒ‰ì–´] {len(expanded_queries)}ê°œ")
    progress_logs.append(f"[ì´ ë°œê²¬ëœ ì •ë³´] {len(key_findings)}ê°œ")
    progress_logs.append(f"[ìµœì¢… ë³´ê³ ì„œ í¬ê¸°] {len(report)} ì")
    
    # ë¡œê·¸ íŒŒì¼ ì €ì¥ (ëª¨ë“  raw ë°ì´í„° ë° ì¤‘ê°„ ê³¼ì • í¬í•¨)
    log_path = save_logs_to_file(
        progress_logs, 
        query, 
        timestamp, 
        search_results=search_results,
        expanded_queries=expanded_queries_text,
        findings=findings_text,
        report=report
    )
    
    yield update_ui("\nâœ¨ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", expanded_queries_text, findings_text, report, report_path, log_path)
    yield update_ui(f"ğŸ“„ ë³´ê³ ì„œê°€ '{report_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", expanded_queries_text, findings_text, report, report_path, log_path)
    yield update_ui(f"ğŸ“‹ ì „ì²´ ê³¼ì • ìƒì„¸ ë¡œê·¸ê°€ '{log_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", expanded_queries_text, findings_text, report, report_path, log_path)
    
    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return (
        "\n".join(progress_logs[-15:]),  # UIì—ëŠ” ìµœê·¼ 15ê°œ ë©”ì‹œì§€ë§Œ í‘œì‹œ
        expanded_queries_text,
        findings_text,
        report,
        report_path,
        log_path
    )

def create_gradio_interface():
    with gr.Blocks(title="ë©€í‹° ì—ì´ì „íŠ¸ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ¤– ë©€í‹° ì—ì´ì „íŠ¸ ë¦¬ì„œì¹˜ ì‹œìŠ¤í…œ")
        gr.Markdown("ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´, AI ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ë ¥í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.")
        
        with gr.Row():
            with gr.Column(scale=1):
                # ì…ë ¥
                query_input = gr.Textbox(
                    label="ê²€ìƒ‰ ì£¼ì œ",
                    placeholder="ì˜ˆ: ë²šê½ƒ ê°œí™”ì‹œê¸°",
                    lines=2
                )
                search_button = gr.Button("ğŸ” ê²€ìƒ‰ ì‹œì‘", variant="primary")
            
            with gr.Column(scale=2):
                # ì§„í–‰ ìƒí™©
                progress_output = gr.Textbox(
                    label="ì§„í–‰ ìƒí™©",
                    lines=15,
                    interactive=False
                )
        
        with gr.Row():
            with gr.Column():
                # í™•ì¥ëœ ì¿¼ë¦¬
                expanded_queries_output = gr.Textbox(
                    label="í™•ì¥ëœ ê²€ìƒ‰ì–´",
                    lines=5,
                    interactive=False
                )
                # ì£¼ìš” ë°œê²¬ì‚¬í•­
                findings_output = gr.Textbox(
                    label="ì£¼ìš” ë°œê²¬ì‚¬í•­",
                    lines=10,
                    interactive=False
                )
            
            with gr.Column():
                # ìµœì¢… ë³´ê³ ì„œ
                report_output = gr.Textbox(
                    label="ìµœì¢… ë³´ê³ ì„œ",
                    lines=20,
                    interactive=False
                )
                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                with gr.Row():
                    # ë³´ê³ ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                    file_output = gr.File(
                        label="ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        interactive=False
                    )
                    # ë¡œê·¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                    log_file_output = gr.File(
                        label="ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
                        interactive=False
                    )
        
        # ì´ë²¤íŠ¸ ì—°ê²°
        search_button.click(
            fn=process_query,
            inputs=query_input,
            outputs=[
                progress_output,
                expanded_queries_output,
                findings_output,
                report_output,
                file_output,
                log_file_output
            ],
            show_progress=False
        )
    
    return interface

if __name__ == "__main__":
    interface = create_gradio_interface()
    interface.launch(
        server_name="0.0.0.0",
        share=True,
        show_error=True
    ) 